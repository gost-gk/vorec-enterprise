# Обновлённый вореционный генератор с поддержкой указателей

С кратким описанием вореций можно ознакомиться в [репозитории](https://github.com/1024--/voretions) уважаемого кобенатора *1024--*.


## Установка
Генератор имеет дополнительную зависимость в виде [стеммера PyStemmer](https://github.com/snowballstem/pystemmer). Для Питона версий 3.6 и ниже его можно установить через `pip install pystemmer`, а вот в 3.7 господа питонисты поломали совместимость, и стеммер перестал конпелироваться. 
Однако, не всё потеряно: можно вручную пропатчить/похакать сгенерированный Cython'он код. Для этого:
1. Загружаем стеммер (`pip download pystemmer`).
2. Распаковываем. 
3. Идём ~~напитон~~ в  `PyStemmer-1.3.0/src`, открываем `Stemmer.c`.
4. ~~Вилкой чистим~~ заменяем все `tstate->exc_type`, `tstate->exc_value` и `tstate->exc_traceback` на `tstate->exc_state.exc_type`, `tstate->exc_state.exc_value` и `tstate->exc_state.exc_traceback` соответственно. Тем, кому лень — вот уже почищенный [гист](https://gist.github.com/gost-gk/2c122b1024ce34e6e461293eff903685).
5. После этого просто делаем `python setup.py build && python setup.py install`.

Насколько этот хак работоспособен — хз, на продакшен бы я это не пускал. А для работы генератора стабильности хватает.

## Краткое описание генератора
Обновлённый кобенный генератор состоит из нескольких скриптов ~~(модульность! переиспользование кода! сцепление!)~~:
* `markov.py`: простая реализация цепи Маркова с подсчётом одинаковых элементов. Сгенерировать цепь можно либо в автоматическом режиме через `convert_words_list()` (принимает список `L` элементов и заносит в цепь пары вида `(L[i], L[i + 1])` для каждого i из диапазона `[0; len(L) - 1)`), либо вручную добавляя пары через `add_pair()`. Получать следующий элемент можно функцией `get_next_word()`, которая принимает исходный элемент и функцию генерации пустого элемента (как в `defaultdict`).
* `text_util.py`: сборная солянка из функций для обработки текста: очистки, разбиения на слова, стеммирования слов:
    - `class Word`: простое представление слова в виде основы (`root`) и окончания (`suffix`).
    - `class PunctedWord(Word)`: то же самое, что и `Word`, только с добавлением опционального знака препинания.
    - `is_punct(word)`: является ли входная строка `word` знаком препинания. Может принимать `Word`/`PunctedWord`.
    - `stem_word(word)`: разбивает строку `word` на корень и окончание, возвращает `Word`.
    - `fix_multiple_spaces(text)`: нормализация пробелов: заменяет в строке `text` все подряд идущие пробельные символы на один пробел.
    - `clear_input_text(text)`: очистка прочитанного из файла текста: убирает переносы строк и нормализует пробелы.
    - `split_text_alnum(text)`: разбивает текст на список слов, каждое из которых состоит только из букв, цифр и опционального дефиса (например, как в слове `по-петушиному`). Каждое получанное слово стеммируется, и в результате возвращается список из `Word`'ов.
    - `split_text_punct(text)`: то же, что и `split_text_alnum`, но при этом в возвращаемом списке отдельными словами будут стоять знаки препинания. Эта функция нужна для создания цепи Маркова, генерирующей пунктуационные вореции (на входе — основа слова, на выходе — встречающиеся после него знаки препинания).
* `ptr_natal.py`: натализация итогового текста указателями (указателефикация). Указателефикация проводится функцией `natal_ptr_words_list(words)`, которая принимает список из `PunctedWord` и возвращает модифицированный список из них же. Находится в разработке.
* `pp_vorec.py`: основной файл кобенного генератора. Генерация вореций происходит в функции `generate_words_list`, принимающей исходный текст и ограничения на максимальное количество слов/символов. Олгоритм работы генератора следующий:
    1. Переводим входной текст в нижний регистр, очищаем его и разбиваем на два списка — слов и слов со знаками препинания.
    2. Генерируем основную цепь `chain`, состоящую из основ (корней) слов. На её входе — основы слов, на выходе — полные слова (`str -> Word`).
    3. Генерируем вспомогательную цепь `punct_chain`, на входе которой — основа слова, а на выходе — либо знак препинания, либо пустая строка.
    4. Генерируем вспомогательную цепь `suffix_chain`, на вход которой подаём пары вида `(окончание предыдущего слова, основа текущего слова)`, а на выходе получаем суффикс текущего слова.
    5. В цикле до тех пор, пока не достигли ограничений на количество слов/символов:
        1. Сохраняем текущее слово в предыдущее (`prev_word`) для генерации пунктуационных вореций.
        2. Если текущее слово (`next_word`) пустое — берём случайное слово из входной психозы, иначе — генерируем следующее слово на основе корня текущего (`next_word = chain.get_next_word(next_word.root, lambda: Text.Word(''))`).
        3. Генерируем окончание текущего слова на основе окончания предыдущего и корня текущего. Если не сгенерировали (цепь возвратила пустую строку) — используем окончание текущего слова.
        4. Генерируем знак препинания на основе корня текущего слова.
        5. Если мы сгенерировали первое слово, либо же предыдущее слово закончило предложение (`PunctedWord.punct` оказался равен `.`, `!` или `?`) — капитализируем текущее.
        6. Добавим в выходной список слов текущее слово.
        
Остальные функции просты и не требуют пояснения.